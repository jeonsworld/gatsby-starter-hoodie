---
title: "KANs 대 MLPs: 새로운 AI 네트워크의 등장과 그 의미"
description: "KANs 대 MLPs: 새로운 AI 네트워크의 등장과 그 의미"
date: 2024-05-07
update: 2024-05-07
tags:
  - KANs
  - MLPs
  - 학습 가능한 활성화 함수
---

### **학습 가능한 활성화 함수가 전부일까요?**

이론적인 논문들은 보통 우리의 관심사를 벗어나지만, 오늘은 그만큼의 드라마가 있고 다른 일은 별로 없어서 이에 대해 이야기할 여유가 있습니다. 일주일 전, Max Tegmark의 대학원생 [Ziming Liu가 그의 논문을 발표했습니다](https://arxiv.org/abs/2404.19756). 이 논문은 KANs(Kolmogorov-Arnold Networks)가 MLPs(Multi-Layer Perceptrons)보다 거의 모든 중요한 차원에서 우월하거나 동등하다고 주장하며, [해석 가능성](https://x.com/ZimingLiu11/status/1785489972218433627)/[유도 편향 주입](https://x.com/ZimingLiu11/status/1785490122303287346), [함수 근사 정확도](https://x.com/ZimingLiu11/status/1785489587122601997) 및 확장성에서 그러합니다. 현재 하드웨어에서는 훈련 속도가 [10배 느리지만](https://www.reddit.com/r/MachineLearning/comments/1chrafb/comment/l24eymi/), [100배 더 매개변수 효율적이라고](https://www.reddit.com/r/MachineLearning/comments/1chrafb/comment/l24fp48/) 인정받고 있습니다.

![KANs 이미지](https://assets.buttondown.email/images/f3be6c78-f460-49bc-b7be-b0a4fce9f5d8.png?w=960&fit=max)

KANs는 ReLu와 같은 사전 설정된 활성화 함수를 층화하는 대신, [B-splines](https://ocw.mit.edu/courses/18-085-computational-science-and-engineering-i-fall-2008/resources/lecture-21-boundary-conditions-splines-gradient-divergence/)을 사용하여 '학습 가능한 활성화 함수'를 모델링합니다(즉, 선형 가중치 없이 곡선만 사용). 사람들은 이에 흥분하여 [KANs로 GPT를 재작성하기 시작했습니다](https://x.com/predict_addict/status/1787853844862378463). 하지만 일주일 후, KAN 용어를 재배열하여 MLPs로 돌아갈 수 있다는 것이 밝혀졌습니다([트위터 소스](https://twitter.com/bozavlado/status/1787376558484709691)).

![MLP 이미지](https://assets.buttondown.email/images/99ec5339-40b6-45e4-a8e3-e3ef52a2078b.png?w=960&fit=max)

이는 하나의 보편적 근사자를 다른 것으로 재작성할 수 있다는 것에 놀라운 것은 아니지만, 이 매우 간단한 출판을 따라 많은 사람들이 KANs를 더 해석 가능하다고 옹호하고 있습니다. 이는 또한 [정당하게 도전받고 있습니다](https://x.com/FreeFooooooood/status/1787403148442718696).

한 주 만에 새로운 이론 논문의 전체 상승과 하락을 목격했습니까? 이것이 사전 인쇄 시스템이 작동하는 것일까요?

## Today's Preview
* **OpenAI와 GPT 모델**
  - **GPT-5 출시 가능성**: [@bindureddy](https://twitter.com/bindureddy/status/1787844680182555052)는 gpt-2 챗봇이 chat.lmsys에서 다시 활성화되었으며, 이는 최신 GPT-5 버전일 수 있지만, 기대에 비해 실망스럽다고 언급했습니다. [@nptacek](https://twitter.com/nptacek/status/1787798590741458976)은 im-a-good-gpt2-chatbot 모델을 테스트하여 매우 강력하고 **확실히 GPT-4보다 낫다**고 발견했습니다. im-also-a-good-gpt2-chatbot은 빠른 출력을 제공하지만 반복적인 루프에 빠지는 경향이 있습니다.
  - **OpenAI 안전 테스트**: [@zacharynado](https://twitter.com/zacharynado/status/1787864594553184427)는 OpenAI의 GPT-4.5 안전 테스트가 Google I/O 출시에 맞춰 완료되지 않았다고 추측했습니다.
  - **AI 생성 이미지 감지**: OpenAI는 AI 생성 이미지 및 비디오의 출처를 인증하는 C2PA 메타데이터 표준을 채택했습니다. [@rohanpaul_ai](https://twitter.com/rohanpaul_ai/status/1787853748682805631)는 분류기가 DALL-E 3 이미지의 약 98%를 식별하면서 0.5% 미만의 비 AI 이미지를 잘못 표시한다고 언급했습니다. 그러나 DALL-E 3와 다른 AI 생성 이미지를 구분하는 성능은 낮습니다.
* **Microsoft AI 개발**
  - **자체 LLM 훈련**: [@bindureddy](https://twitter.com/bindureddy/status/1787498838024139185)에 따르면, Microsoft는 자체 500B 매개변수 모델인 MAI-1을 훈련 중이며, Build 컨퍼런스에서 미리 보기가 가능할 것입니다. 모델이 사용 가능해지면 Microsoft는 OpenAI의 GPT 라인 대신 자체 모델을 밀어붙일 것입니다. 이로 인해 두 회사 간의 경쟁이 더욱 치열해질 것입니다.
  - **Copilot Workspace 인상**: [@svpino](https://twitter.com/svpino/status/1787893785814249780)는 Copilot Workspace에 대한 첫 인상이 매우 긍정적이라고 언급했습니다. 이 도구는 GitHub과 긴밀하게 통합되어 코드를 직접 생성하고 문제를 해결하며 테스트하는 데 도움이 됩니다. 이 도구는 개발자를 대체하기보다는 도움을 주는 것으로 위치하고 있습니다.
  - **Microsoft의 AI 초점**: [@mustafasuleyman](https://twitter.com/mustafasuleyman/status/1787580620694077639)은 Microsoft에 합류한 후 회사가 AI를 우선시하고 기술적 변혁을 주도하고 있으며, **책임 있는 AI를 핵심 요소**로 삼고 있다고 공유했습니다. 팀들은 새로운 규범을 정의하고 긍정적인 영향을 미치는 제품을 만들기 위해 노력하고 있습니다.

### AI Viewpoint 🤖
> KANs와 MLPs의 비교는 인공지능 분야에서 중요한 발전을 나타냅니다. KANs가 제안하는 '학습 가능한 활성화 함수'는 기존의 MLPs와 비교했을 때 흥미로운 대안을 제시하지만, 실제로 MLPs로 재구성될 수 있다는 최근의 발견은 이러한 새로운 접근법이 기존 방법론에 얼마나 가까운지를 보여줍니다. 이는 AI 연구에서의 혁신이 단순히 새로운 아이디어의 도입만이 아니라, 기존의 이론과 방법론을 재해석하고 개선하는 과정에서도 발생한다는 것을 강조합니다. 또한, 이러한 이론적 논의가 실제 응용으로 어떻게 전환될 수 있는지에 대한 더 깊은 통찰을 제공합니다.

## Today's Overview
### 최신 인공지능 기술과 응용 분야의 종합 리포트

**1. 인공지능 기술의 최신 동향**
- **Llama3 모델과 GGUF 변환 문제**: Llama3 모델을 GGUF로 변환하는 과정에서 데이터 유지에 버그가 발견되었습니다. 이 문제는 GitHub의 [Issue #7062](https://github.com/ggerganov/llama.cpp/issues/7062)와 Reddit 스레드에서 활발히 논의되고 있습니다.
- **모델 훈련의 팁과 문제점**: LORA 어댑터를 사용한 성공적인 활용 사례가 있었으나, 기본 데이터가 미세 조정된 모델 결과에 영향을 미칠 수 있다는 우려가 제기되었습니다.
- **AI 엔진의 호환성 문제**: Aphrodite 엔진의 4bit bnb 양자화와의 호환성에 대한 질문이 제기되었으며, GGUF 및 exllama와 같은 모델에 대한 VRAM 계산기가 참조되었습니다.

**2. 인공지능 기술의 향후 전망**
- **기능 호출 성능 비교**: Llama 3 70b가 Mistral 8x22b보다 기능 호출 성능이 우수함을 보여주었습니다. 이는 AI 챗봇에서의 유틸리티와 정확성에 대한 논의로 이어졌습니다.
- **AI 훈련 속도의 비교**: LoRA llama 3 8b 튜닝에 500초가 소요되었고, Llama2 7B는 1,000회 반복에 3분이 소요되었습니다. 이는 효율성과 최적화에 대한 질문을 제기합니다.

**3. 인공지능의 신뢰성 추구**
- **'Deterministic Quoting' 도입**: Invetech가 신뢰할 수 있는 AI를 목표로 'Deterministic Quoting'을 도입했습니다. 이는 특히 의료 분야에서 AI의 정확성을 높이는 데 중점을 두고 있습니다. ([논의](https://mattyyeung.github.io/deterministic-quoting))

**4. 개방형 AI의 미래에 대한 우려**
- **Stable Diffusion 모델의 개방성 문제**: Stable Diffusion 3의 개방 소스 여부에 대한 우려가 커지고 있습니다. 이는 AI 모델의 전략적 보호에 대한 논의로 이어집니다.

**5. 인공지능 개발자의 프라이버시 보호 요청**
- **LM Studio의 서버 로깅 기능 비활성화 요청**: 개발자들은 개발 중 프라이버시를 보호하기 위해 LM Studio에서 서버 로깅을 비활성화할 수 있는 기능을 요청하고 있습니다.

이러한 정보들은 인공지능 기술의 발전과 그에 따른 다양한 도전 과제들을 보여줍니다. 기술의 진화에 따라 이러한 문제들을 해결하기 위한 새로운 접근 방식과 솔루션이 계속해서 필요할 것입니다.
    
