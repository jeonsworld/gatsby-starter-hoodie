---
title: "Kaggle 콘테스트에서 인간 선호도 예측을 위한 $100k 도전"
description: "Kaggle 콘테스트에서 인간 선호도 예측을 위한 $100k 도전"
date: 2024-05-04
update: 2024-05-04
tags:
  - Kaggle 도전
  - LLM 선호도 예측
  - AI 벤치마킹
---
    
    
이번 주 AI 뉴스는 조용한 편이었습니다. [이곳](https://lmsys.org/blog/2024-05-02-kaggle-competition/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-not-much-happened-today-3049)에서 새로운 Kaggle 도전이 시작되었습니다: 사용자가 LLM 응답 사이에서 선호하는 것을 예측하는 $100k Kaggle 경연대회가 발표되었습니다. 이 대회는 55K 사용자/LLM 대화가 포함된 새로운 데이터셋을 기반으로 합니다.

## Today's Preview
* **LLM 모델 릴리스 및 벤치마킹**
  - [DrJimFan](https://twitter.com/DrJimFan/status/1786429467537088741?utm_source=ainews&utm_medium=email&utm_campaign=ainews-not-much-happened-today-3049)은 시뮬레이션에서 로봇 기술을 훈련시키는 LLM 에이전트 DrEureka를 발표했고, 실제 세계로의 제로샷 전환을 가능하게 합니다. [GroqInc](https://twitter.com/awnihannun/status/1786066330501956053?utm_source=ainews&utm_medium=email&utm_campaign=ainews-not-much-happened-today-3049)의 Llama 3 70B 모델은 성능 기록을 갱신하고 있으며, 입력 토큰당 $0.65, 출력 토큰당 $0.9의 비용으로 운영됩니다.
* **데이터셋 및 벤치마킹**
  - [percyliang](https://twitter.com/percyliang/status/1786256267138478475?utm_source=ainews&utm_medium=email&utm_campaign=ainews-not-much-happened-today-3049)은 새로운 GSM1K 데이터셋에서 모델이 프롬프트에 민감하게 반응하여 샘플링과 다수결 투표가 필요하다고 논의했습니다.
* **효율적인 LLM 훈련 및 추론 기술**
  - [NVIDIA](https://twitter.com/_akhaliq/status/1786222861666971804?utm_source=ainews&utm_medium=email&utm_campaign=ainews-not-much-happened-today-3049)는 LLM 정렬 기술인 RLHF, DPO, SteerLM, SPIN을 효율적으로 활용할 수 있는 NeMo-Aligner라는 확장 가능한 툴킷을 소개했습니다.

### AI Viewpoint 🤖
> 이번 Kaggle 도전은 LLM의 대화형 응답에 대한 사용자의 선호도를 예측하는 것을 목표로 하며, 이는 인공지능이 인간의 선호와 반응을 얼마나 잘 이해하고 반영할 수 있는지를 평가하는 데 중요한 기준이 될 수 있습니다. 이러한 경연대회는 AI 연구와 개발에 있어서 중요한 동기부여가 되며, 실제 사용자와의 상호작용을 통해 얻은 데이터를 기반으로 한다는 점에서 그 가치가 더욱 높아집니다.

# Today's Overview
### 최신 인공지능 기술과 응용 분야의 종합 리포트

**1. 최신 인공지능 기술 동향**
- **Triton과 CUDA의 한계와 협업**: 엔지니어들은 Triton 블록의 한계를 논의하며, 4096 요소 블록은 실행 가능하지만 8192 요소 블록은 실행 불가능함을 확인했습니다. 이는 예상 CUDA 한계와의 불일치를 시사합니다. ([Compiler Explorer](https://godbolt.org/z/9K9Gf1v6P?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **PyTorch와 LLM 추론 최적화**: PyTorch의 `linear` 함수와 행렬 곱셈 커널의 동작을 검토하고, Effort Engine 알고리즘이 LLM 추론 중 계산 노력을 조정할 수 있게 함으로써, Apple Silicon에서 표준 행렬 곱셈과 비슷한 속도를 낼 수 있음을 논의했습니다. ([Effort Engine on kolinko](https://kolinko.github.io/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408), [GitHub](https://github.com/kolinko/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **InstaDeep의 기계학습 엔지니어 채용**: InstaDeep은 고성능 ML 엔지니어링, 사용자 정의 CUDA 커널 및 분산 훈련에 능숙한 기계 학습 엔지니어를 채용 중입니다. ([InstaDeep Careers](https://www.instadeep.com/job-offer/92900fa3-5501-4506-a63f-cebee958fc6f/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))

**2.인공지능 기술의 향후 전망**
- **LLM의 컨텍스트 길이 증가**: Llama-3 8B 모델이 컨텍스트 길이 증가를 통해 새로운 벤치마크를 설정했습니다. 이는 LLM의 가능성을 크게 확장시키는 발전입니다. ([Llama-3 8B Gradient Instruct 1048k](https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **ROCm과 Flash Attention 2의 적응**: ROCm 채널에서는 NVIDIA의 Flash Attention 2를 ROCm에 적용하는 논의가 있었습니다. 이는 ROCm 6.x 버전과의 호환성에 중점을 두고 있습니다. ([ROCm/flash-attention on GitHub](https://github.com/ROCm/flash-attention?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
    
    