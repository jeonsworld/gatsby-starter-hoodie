---
title: "Kaggle 대회에서 LMSYS 인간 선호도 예측에 100,000달러 도전"
description: "Kaggle 대회에서 LMSYS 인간 선호도 예측에 100,000달러 도전"
date: 2024-05-04
update: 2024-05-04
tags:
  - Kaggle 대회
  - LMSYS 인간 선호도
  - LLM 벤치마킹
---

이번 주 AI 뉴스는 조용한 편이었습니다. [여기](https://lmsys.org/blog/2024-05-02-kaggle-competition/)에서 새로운 Kaggle 도전을 확인할 수 있습니다: LMSYS 인간 선호도를 예측하는 100,000달러 상금의 대회가 개최됩니다.

## Today's Preview
* **LLM 모델 출시 및 벤치마크**
  - [DrJimFan](https://twitter.com/DrJimFan/status/1786429467537088741)은 시뮬레이션에서 로봇 기술을 훈련시키는 LLM 에이전트 DrEureka를 발표했으며, 실제 세계로의 제로샷 전환을 가능하게 합니다. [GroqInc](https://twitter.com/awnihannun/status/1786066330501956053)의 Llama 3 70B 모델은 성능 기록을 갱신하고 있습니다. [bindureddy](https://twitter.com/bindureddy/status/1786019505027608646)는 Groq의 Llama 3 모델이 선두를 달리고 있다고 언급했습니다.
  - [DrJimFan](https://twitter.com/DrJimFan/status/1786054643568517261)은 중요한 LLM 평가 유형 세 가지를 제안합니다: 신뢰할 수 있는 제3자가 공개적으로 점수를 보고하는 비공개 테스트 세트, [lmsysorg](https://twitter.com/lmsysorg)의 Chatbot Arena와 같은 공개 비교 벤치마크, 각 회사의 사용 사례에 맞춘 비공개 내부 벤치마크.
  - [ShayneRedford](https://twitter.com/ShayneRedford/status/1786455899059503448)는 인간과 GPT-4 판단을 밀접하게 반영하는 오픈 소스 평가 LLM인 Prometheus 2를 소개했습니다. 이들은 기존 LLM을 능가하는 LM 판사를 구축합니다.
* **데이터셋 및 벤치마킹**
  - [percyliang](https://twitter.com/percyliang/status/1786256267138478475)은 새로운 GSM1K 데이터셋에서 모델이 프롬프트에 민감하다고 언급했습니다. 일부는 추가 힌트로 성능이 저하됩니다.
  - [lmsysorg](https://twitter.com/lmsysorg/status/1786100697504833572)은 LLM 응답 사이의 사용자 선호도를 예측하기 위한 100,000달러 Kaggle 대회를 발표했습니다.
  - [clefourrier](https://twitter.com/clefourrier/status/1785936450577375556)는 모델 생성을 위한 '안전한' 아티팩트 선택을 돕기 위해 모델 및 데이터셋 오염을 추적하는 새로운 오픈 데이터베이스를 소개했습니다.

### AI Viewpoint 🤖
> 이번 Kaggle 대회는 LMSYS 인간 선호도 예측을 통해 LLM의 실제 세계 적용 가능성을 탐구하는 데 중요한 기회를 제공합니다. 대회를 통해 수집된 데이터는 LLM이 인간의 선호를 얼마나 잘 이해하고 반영할 수 있는지에 대한 깊은 통찰을 제공할 것입니다. 또한, 이러한 대회는 AI 커뮤니티에 협력과 경쟁을 촉진하여 기술의 발전을 가속화하는 역할을 합니다.

## Today's Overview
### 최신 인공지능 기술과 응용 분야의 종합 리포트

**1. 최신 인공지능 기술 동향**
- **Triton과 CUDA의 한계와 협업**: 엔지니어들은 Triton 블록의 한계를 논의하며, 4096 요소 블록은 실행 가능하지만 8192 요소 블록은 실행 불가능함을 확인했습니다. 이는 예상 CUDA 한계와의 불일치를 시사합니다. ([Compiler Explorer](https://godbolt.org/z/9K9Gf1v6P?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **PyTorch와 LLM 추론 최적화**: PyTorch의 `linear` 함수와 행렬 곱셈 커널의 동작을 검토하고, Effort Engine 알고리즘이 LLM 추론 중 계산 노력을 조정할 수 있게 함으로써, Apple Silicon에서 표준 행렬 곱셈과 비슷한 속도를 낼 수 있음을 논의했습니다. ([Effort Engine on kolinko](https://kolinko.github.io/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408), [GitHub](https://github.com/kolinko/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **InstaDeep의 기계학습 엔지니어 채용**: InstaDeep은 고성능 ML 엔지니어링, 사용자 정의 CUDA 커널 및 분산 훈련에 능숙한 기계 학습 엔지니어를 채용 중입니다. ([InstaDeep Careers](https://www.instadeep.com/job-offer/92900fa3-5501-4506-a63f-cebee958fc6f/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))

**2.인공지능 기술의 향후 전망**
- **LLM의 컨텍스트 길이 증가**: Llama-3 8B 모델이 컨텍스트 길이 증가를 통해 새로운 벤치마크를 설정했습니다. 이는 LLM의 가능성을 크게 확장시키는 발전입니다. ([Llama-3 8B Gradient Instruct 1048k](https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **ROCm과 Flash Attention 2의 적응**: ROCm 채널에서는 NVIDIA의 Flash Attention 2를 ROCm에 적용하는 논의가 있었습니다. 이는 ROCm 6.x 버전과의 호환성에 중점을 두고 있습니다. ([ROCm/flash-attention on GitHub](https://github.com/ROCm/flash-attention?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
    
