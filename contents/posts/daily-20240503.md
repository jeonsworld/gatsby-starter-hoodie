---
title: "새로운 평가 기준의 등장: AI 벤치마크의 미래"
description: "새로운 평가 기준의 등장: AI 벤치마크의 미래"
date: 2024-05-03
update: 2024-05-03
tags:
  - AI 벤치마크
  - 데이터 오염
  - 멀티모달 모델
---

데이터 및 벤치마크 오염 문제는 종종 농담거리로 여겨졌지만, 올해에는 MMLU 및 GSM8K와 같은 잘 알려진 학술 벤치마크에서 자체 보고된 점수에 대한 신뢰도가 감소하면서 분기점에 이르렀습니다. Scale AI는 새로운 GSM8K 유사 벤치마크를 제안하고, 오염이 덜한 벤치마크를 제시하며, 편차를 그래프로 나타냈습니다. Mistral은 GSM8K에서 두드러지게 과적합하는 경향이 있으며, [Phi-3은 놀라울 정도로 잘 수행합니다](https://twitter.com/SebastienBubeck/status/1785888787484291440). 

![image](https://assets.buttondown.email/images/4737565c-4a53-46ac-8c90-35d1c53b0523.png?w=960&fit=max)

Reka는 멀티모달 모델을 위한 새로운 [VibeEval](https://twitter.com/RekaAILabs/status/1785731738326741103) 벤치마크를 출시했습니다. 이들은 다중 선택 벤치마크가 채팅 모델에 대한 좋고 안정적인 척도가 아니라는 잘 알려진 문제를 해결합니다. 

마지막으로, [Jim Fan의 생각](https://twitter.com/DrJimFan/status/1786054643568517261)을 통해 평가의 미래에 대한 방향을 조명합니다. 

![image](https://assets.buttondown.email/images/349c2690-700a-4c54-bdd5-ef9a74d0d97a.png?w=960&fit=max)

## Today's Preview
* AI 개발 및 기능
  - GPT-4 이후: OpenAI의 CEO Sam Altman은 GPT-4를 '멍청하고 부끄러운' 것으로 언급하며, GPT-5의 출시가 임박했음을 시사합니다. Altman은 사용자의 작업을 도와주고 개인 정보에 접근할 수 있는 AI 에이전트가 다음 큰 돌파구가 될 것이라고 믿으며, 사용자의 삶에 대해 모든 것을 아는 ['초능력 동료'](https://www.technologyreview.com/2024/05/01/1091979/sam-altman-says-helpful-agents-are-poised-to-become-ais-killer-function/)를 상상합니다.
  - GPT-3.5 탈옥: 한 연구자가 OpenAI의 미세조정 API를 사용하여 [GPT-3.5를 탈옥하는 방법](https://www.reddit.com/r/OpenAI/comments/1chn1pv/its_actually_very_easy_to_jailbreak_chatgpt_using/)을 시연했습니다. 이는 안전 검사를 우회하여 제한이 없는 LLM에서 생성된 해로운 질문과 답변의 데이터셋으로 모델을 훈련시킴으로써 이루어졌습니다.

### AI Viewpoint 🤖
> 이번 보고서에서 다룬 새로운 벤치마크와 평가 방법들은 AI 연구 및 개발의 미래에 중요한 영향을 미칠 것입니다. 특히, 오염된 데이터 문제를 해결하고 더 정확하고 신뢰할 수 있는 평가 방법을 제시함으로써, AI 모델의 성능을 객관적으로 평가하고 이를 통해 모델의 발전을 도모할 수 있습니다. 또한, 멀티모달 모델을 위한 새로운 벤치마크의 도입은 AI가 다양한 형태의 데이터를 처리하는 능력을 더욱 향상시킬 수 있는 기회를 제공합니다.

## Today's Overview
### 최신 인공지능 기술과 응용 분야의 종합 리포트

**1. 최신 인공지능 기술 동향**
- **Triton과 CUDA의 한계와 협업**: 엔지니어들은 Triton 블록의 한계를 논의하며, 4096 요소 블록은 실행 가능하지만 8192 요소 블록은 실행 불가능함을 확인했습니다. 이는 예상 CUDA 한계와의 불일치를 시사합니다. ([Compiler Explorer](https://godbolt.org/z/9K9Gf1v6P?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **PyTorch와 LLM 추론 최적화**: PyTorch의 `linear` 함수와 행렬 곱셈 커널의 동작을 검토하고, Effort Engine 알고리즘이 LLM 추론 중 계산 노력을 조정할 수 있게 함으로써, Apple Silicon에서 표준 행렬 곱셈과 비슷한 속도를 낼 수 있음을 논의했습니다. ([Effort Engine on kolinko](https://kolinko.github.io/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408), [GitHub](https://github.com/kolinko/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **InstaDeep의 기계학습 엔지니어 채용**: InstaDeep은 고성능 ML 엔지니어링, 사용자 정의 CUDA 커널 및 분산 훈련에 능숙한 기계 학습 엔지니어를 채용 중입니다. ([InstaDeep Careers](https://www.instadeep.com/job-offer/92900fa3-5501-4506-a63f-cebee958fc6f/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))

**2.인공지능 기술의 향후 전망**
- **LLM의 컨텍스트 길이 증가**: Llama-3 8B 모델이 컨텍스트 길이 증가를 통해 새로운 벤치마크를 설정했습니다. 이는 LLM의 가능성을 크게 확장시키는 발전입니다. ([Llama-3 8B Gradient Instruct 1048k](https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **ROCm과 Flash Attention 2의 적응**: ROCm 채널에서는 NVIDIA의 Flash Attention 2를 ROCm에 적용하는 논의가 있었습니다. 이는 ROCm 6.x 버전과의 호환성에 중점을 두고 있습니다. ([ROCm/flash-attention on GitHub](https://github.com/ROCm/flash-attention?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
    
