---
title: "LLMs-as-Juries: 다중 LLM 판사가 단일 판사를 능가하는 새로운 발견"
description: "LLMs-as-Juries: 다중 LLM 판사가 단일 판사를 능가하는 새로운 발견"
date: 2024-05-01
update: 2024-05-01
tags:
  - LLMs-as-Juries
  - 다중 LLM 판사
  - 법률 AI
---


최근 연구에서 다중 에이전트 시스템이 단일 에이전트보다 우수한 성능을 보이는 것이 일반적이라는 것이 밝혀졌습니다. 이러한 맥락에서, [Cohere](https://twitter.com/cohere/status/1785284142789242932?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408)는 LLMs를 사용하여 법정 판사 역할을 하는 시스템에서도 비슷한 결과를 발견했습니다. 이들은 단일 LLM 판사 대신 다중 LLM '배심원'을 사용할 때 더 나은 평가 성능을 보였으며, 비용도 GPT-4를 사용할 때보다 7-8배 저렴했습니다. 이러한 발견은 인공지능이 법률 판단 과정에서 어떻게 활용될 수 있는지에 대한 새로운 시각을 제공합니다.

![LLMs-as-Juries Image](https://assets.buttondown.email/images/ecea573b-f0e8-4e44-968d-82e8f2f4540e.png?w=960&fit=max)

## Today's Preview
* **OpenAI News**
  - Memory 기능이 모든 ChatGPT Plus 사용자에게 제공됩니다. [자세히 보기](https://twitter.com/OpenAI/status/1784992796669096181?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408)
  - OpenAI가 Financial Times와 AI 뉴스 개발을 위한 콘텐츠 라이선스 계약을 체결했습니다. [자세히 보기](https://www.reuters.com/technology/financial-times-openai-sign-content-licensing-partnership-2024-04-29/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408)
* **LLMs and AI Models**
  - Llama 3 모델이 32k 컨텍스트에서 뛰어난 품질을 보여줍니다. [자세히 보기](https://twitter.com/abacaj/status/1785147493728039111?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408)
  - LLM을 평가하는 새로운 방법인 'PoLL' 방법이 제안되었습니다. [자세히 보기](https://twitter.com/cohere/status/1785284142789242932?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408)

### AI Viewpoint 🤖
이번 연구는 LLMs가 단일 판사 역할보다 다중 판사 역할에서 더 효과적일 수 있음을 보여줍니다. 이는 향후 법률 분야에서 AI의 활용 가능성을 넓히는 중요한 발견으로, 비용 효율성과 정확성을 동시에 추구하는 새로운 방법론을 제시합니다. 다만, 이러한 시스템의 윤리적, 법적 책임과 투명성 확보가 중요한 과제로 남아 있습니다.

# Today's Overview
## 최신 인공지능 기술 동향과 통찰 리포트

### **1. 최신 인공지능 기술 동향**
- **Triton과 CUDA의 한계와 협업**: 엔지니어들은 Triton 블록의 한계를 논의하며, 4096 요소 블록은 실행 가능하지만 8192 요소 블록은 실행 불가능함을 확인했습니다. 이는 예상 CUDA 한계와의 불일치를 시사합니다. ([Compiler Explorer](https://godbolt.org/z/9K9Gf1v6P?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **PyTorch와 LLM 추론 최적화**: PyTorch의 `linear` 함수와 행렬 곱셈 커널의 동작을 검토하고, Effort Engine 알고리즘이 LLM 추론 중 계산 노력을 조정할 수 있게 함으로써, Apple Silicon에서 표준 행렬 곱셈과 비슷한 속도를 낼 수 있음을 논의했습니다. ([Effort Engine on kolinko](https://kolinko.github.io/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408), [GitHub](https://github.com/kolinko/effort?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **InstaDeep의 기계학습 엔지니어 채용**: InstaDeep은 고성능 ML 엔지니어링, 사용자 정의 CUDA 커널 및 분산 훈련에 능숙한 기계 학습 엔지니어를 채용 중입니다. ([InstaDeep Careers](https://www.instadeep.com/job-offer/92900fa3-5501-4506-a63f-cebee958fc6f/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))

#### **2. 인공지능 기술의 향후 전망**
- **LLM의 컨텍스트 길이 증가**: Llama-3 8B 모델이 컨텍스트 길이 증가를 통해 새로운 벤치마크를 설정했습니다. 이는 LLM의 가능성을 크게 확장시키는 발전입니다. ([Llama-3 8B Gradient Instruct 1048k](https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **ROCm과 Flash Attention 2의 적응**: ROCm 채널에서는 NVIDIA의 Flash Attention 2를 ROCm에 적용하는 논의가 있었습니다. 이는 ROCm 6.x 버전과의 호환성에 중점을 두고 있습니다. ([ROCm/flash-attention on GitHub](https://github.com/ROCm/flash-attention?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))

#### **3. 교육 및 커뮤니티 참여의 중요성**
- **AI 교육의 확장**: MIT는 2024년을 위해 딥러닝 입문 과정을 업데이트했습니다. 이는 AI 및 딥러닝 기술에 대한 이해를 높이고 더 많은 사람들이 기술을 접할 수 있게 합니다. ([MIT Deep Learning Course](https://www.youtube.com/watch?v=ErnWZxJovaM&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=2&utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))
- **커뮤니티 기반 학습의 강화**: Hugging Face는 커뮤니티 기반의 컴퓨터 비전 과정을 시작했습니다. 이는 학습자들이 상호작용하며 학습할 수 있는 기회를 제공합니다. ([Community Computer Vision Course](https://huggingface.co/learn/computer-vision-course/unit0/welcome/welcome?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-4408))

이러한 동향과 전망은 인공지능 기술의 미래에 대한 흥미로운 통찰을 제공하며, 기술의 발전이 어떻게 다양한 분야에 영향을 미칠 수 있는지를 보여줍니다.

